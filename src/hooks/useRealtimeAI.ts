"use client";

import { useRef, useCallback, useState } from "react";

/**
 * ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ AIçµ±åˆãƒ•ãƒƒã‚¯ï¼ˆWebRTCç‰ˆï¼‰
 * Stage 10.2: WebRTC + OpenAI Realtime API
 *
 * ãƒã‚¤ã‚¯éŸ³å£°ã‚’ç›´æ¥OpenAIã«é€ä¿¡ã—ã€éŸ³å£°/ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ã‚’å—ã‘å–ã‚‹
 */

type Transcript = {
  id: string;
  speaker: string;
  text: string;
  timestamp: string;
  isFinal: boolean;
};

type AIResponse = {
  audio?: ArrayBuffer;
  text: string;
  timestamp: string;
};

type OutputMode = "text" | "audio" | "text_audio";

export function useRealtimeAI(
  meetingId: string,
  onTranscript: (transcript: Transcript) => void,
  onAIResponse: (response: AIResponse) => void
) {
  const [isConnected, setIsConnected] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const peerConnectionRef = useRef<RTCPeerConnection | null>(null);
  const dataChannelRef = useRef<RTCDataChannel | null>(null);
  const audioElementRef = useRef<HTMLAudioElement | null>(null);

  // ã‚²ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ç”¨ã®çŠ¶æ…‹
  const lastSpeechTimeRef = useRef<number>(Date.now());
  const lastAIResponseTimeRef = useRef<number>(0);
  const speakerStartTimeRef = useRef<Record<string, number>>({});
  const silenceTimerRef = useRef<NodeJS.Timeout | null>(null);

  // ä¼šè©±å±¥æ­´ã®ä¿æŒï¼ˆæœ€æ–°10ä»¶ï¼‰
  const conversationHistoryRef = useRef<Transcript[]>([]);

  // ä½¿ç”¨é‡ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
  const usageRef = useRef({
    totalInputTokens: 0,
    totalOutputTokens: 0,
    totalInputAudioTokens: 0,
    totalOutputAudioTokens: 0,
    totalCostUSD: 0,
    totalCostJPY: 0,
    responseCount: 0,
  });

  /**
   * ä½¿ç”¨é‡ã‹ã‚‰æ–™é‡‘ã‚’è¨ˆç®—ï¼ˆUSD + JPYï¼‰
   */
  const calculateCost = useCallback(
    (
      inputTokens: number,
      outputTokens: number,
      inputAudioTokens: number,
      outputAudioTokens: number
    ) => {
      // OpenAI Realtime API æ–™é‡‘ï¼ˆæœ€æ–°: 2025å¹´1æœˆæ™‚ç‚¹ï¼‰
      // gpt-realtime (gpt-4o-realtime)
      const RATE_TEXT_INPUT = 4.0 / 1_000_000; // $4.00 per 1M tokens
      const RATE_TEXT_OUTPUT = 16.0 / 1_000_000; // $16.00 per 1M tokens
      const RATE_AUDIO_INPUT = 32.0 / 1_000_000; // $32.00 per 1M tokens (éŸ³å£°ãƒ¢ãƒ¼ãƒ‰)
      const RATE_AUDIO_OUTPUT = 64.0 / 1_000_000; // $64.00 per 1M tokens (éŸ³å£°ãƒ¢ãƒ¼ãƒ‰)

      // USD â†’ JPY æ›ç®—ãƒ¬ãƒ¼ãƒˆ
      const USD_TO_JPY = 154;

      const textInputCost = inputTokens * RATE_TEXT_INPUT;
      const textOutputCost = outputTokens * RATE_TEXT_OUTPUT;
      const audioInputCost = inputAudioTokens * RATE_AUDIO_INPUT;
      const audioOutputCost = outputAudioTokens * RATE_AUDIO_OUTPUT;

      const totalCostUSD =
        textInputCost + textOutputCost + audioInputCost + audioOutputCost;
      const totalCostJPY = totalCostUSD * USD_TO_JPY;

      return {
        textInputCost,
        textOutputCost,
        audioInputCost,
        audioOutputCost,
        totalCostUSD,
        totalCostJPY,
      };
    },
    []
  );

  /**
   * ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ AIæ¥ç¶šé–‹å§‹ï¼ˆWebRTCï¼‰
   */
  const connect = useCallback(
    async (sessionId: string) => {
      try {
        console.log("Starting WebRTC connection to OpenAI Realtime API...");

        // 1. ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ä¸€æ™‚ãƒˆãƒ¼ã‚¯ãƒ³ã¨è¨­å®šã‚’å–å¾—
        const tokenResponse = await fetch("/api/realtime/token", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ meetingId, sessionId }),
        });

        if (!tokenResponse.ok) {
          throw new Error("Failed to get token");
        }

        const {
          openaiEphemeralKey,
          meetingTitle,
          outputMode,
        }: {
          openaiEphemeralKey: string;
          meetingTitle: string;
          outputMode: OutputMode;
        } = await tokenResponse.json();

        if (!openaiEphemeralKey) {
          throw new Error("Failed to get OpenAI ephemeral key");
        }

        console.log("Ephemeral key obtained, output mode:", outputMode);

        // 2. RTCPeerConnectionä½œæˆ
        const pc = new RTCPeerConnection();

        // 3. ãƒã‚¤ã‚¯ã‹ã‚‰éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ å–å¾—
        console.log("Requesting microphone access...");
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            channelCount: 1,
            sampleRate: 24000, // OpenAIæ¨å¥¨
            echoCancellation: true,
            noiseSuppression: true,
          },
        });

        // 4. éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯ã‚’PeerConnectionã«è¿½åŠ 
        const audioTrack = stream.getTracks()[0];
        pc.addTrack(audioTrack, stream);
        console.log("Audio track added to peer connection");

        // 5. éŸ³å£°å‡ºåŠ›ç”¨ã®audioè¦ç´ ä½œæˆ
        if (outputMode === "audio" || outputMode === "text_audio") {
          const audioEl = document.createElement("audio");
          audioEl.autoplay = true;
          audioElementRef.current = audioEl;

          pc.ontrack = (e) => {
            console.log("Received remote audio track");
            audioEl.srcObject = e.streams[0];
          };
        }

        // 6. ãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒãƒ«ä½œæˆï¼ˆã‚¤ãƒ™ãƒ³ãƒˆé€å—ä¿¡ç”¨ï¼‰
        const dc = pc.createDataChannel("oai-events");
        dataChannelRef.current = dc;

        dc.onopen = () => {
          console.log("Data channel opened");

          // ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šã‚’é€ä¿¡
          const sessionConfig = {
            type: "session.update",
            session: {
              modalities:
                outputMode === "text"
                  ? ["text"]
                  : outputMode === "audio"
                    ? ["audio"]
                    : ["text", "audio"],
              instructions: `ã‚ãªãŸã¯ä¼šè­°ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ŒMitonã€ã§ã™ã€‚

ã€è¨€èªè¨­å®šã€‘
å¿…ãšæ—¥æœ¬èªã®ã¿ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚è‹±èªã‚„ä»–ã®è¨€èªã‚’ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚

ä¼šè­°ã‚¿ã‚¤ãƒˆãƒ«: ${meetingTitle}

ã€é‡è¦ã€‘ã‚ãªãŸã¯ä¼šè­°ã®ã€Œ1å‚åŠ è€…ã€ã¨ã—ã¦æŒ¯ã‚‹èˆã„ã¾ã™ã€‚å¸¸ã«ç™ºè¨€ã™ã‚‹ã®ã§ã¯ãªãã€å¿…è¦ãªæ™‚ã ã‘ç™ºè¨€ã—ã¦ãã ã•ã„ã€‚

ã€ç™ºè¨€æ¡ä»¶ï¼ˆå³å®ˆï¼‰ã€‘
ä»¥ä¸‹ã®å ´åˆã®ã¿ç™ºè¨€ã—ã¦ãã ã•ã„ï¼š

1. ç›´æ¥å‘¼ã°ã‚ŒãŸæ™‚
   - ã€ŒMitonã€ã€ŒAIã€ã€Œã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ã¨å‘¼ã°ã‚ŒãŸæ™‚
   - ä¾‹ï¼šã€ŒMitonã•ã‚“ã€ã©ã†æ€ã„ã¾ã™ã‹ï¼Ÿã€

2. è¦ç´„ãƒ»æ•´ç†ã‚’ä¾é ¼ã•ã‚ŒãŸæ™‚
   - ã€Œã¾ã¨ã‚ã¦ã€ã€Œæ•´ç†ã—ã¦ã€ã€Œè¦ç´„ã—ã¦ã€ã¨è¨€ã‚ã‚ŒãŸæ™‚
   - å‚åŠ è€…ã®è©±ãŒ30ç§’ä»¥ä¸Šç¶šã„ãŸå¾Œã€ã€Œè¦ç´„ã—ã¾ã—ã‚‡ã†ã‹ï¼Ÿã€ã¨ææ¡ˆå¯èƒ½

3. è³ªå•ã‚’å—ã‘ãŸæ™‚
   - ã€Œã©ã†æ€ã†ï¼Ÿã€ã€Œæ„è¦‹ã¯ï¼Ÿã€ãªã©ã®è³ªå•å½¢å¼

4. è­°è«–ãŒåœæ»ã—ã¦ã„ã‚‹æ™‚
   - 10ç§’ä»¥ä¸Šæ²ˆé»™ãŒç¶šã„ãŸå ´åˆã€è­°è«–ã‚’ä¿ƒã™è³ªå•ã‚’æŠ•ã’ã‹ã‘ã‚‹
   - ä¾‹ï¼šã€Œã“ã®ç‚¹ã«ã¤ã„ã¦ã€çš†ã•ã‚“ã®ã”æ„è¦‹ã¯ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ï¼Ÿã€

5. æ˜ç¢ºãªèª¤ã‚Šã‚„çŸ›ç›¾ã‚’æ¤œå‡ºã—ãŸæ™‚
   - é‡è¦ãªäº‹å®Ÿèª¤èªãŒã‚ã‚‹å ´åˆã®ã¿ã€ä¸å¯§ã«è¨‚æ­£ææ¡ˆ

ã€çµ¶å¯¾ç¦æ­¢äº‹é …ã€‘
âŒ ä¸Šè¨˜æ¡ä»¶ä»¥å¤–ã§ã®è‡ªç™ºçš„ç™ºè¨€
âŒ ç›¸æ§Œã‚„æŒ¨æ‹¶ï¼ˆã€Œãªã‚‹ã»ã©ã€ã€Œåˆ†ã‹ã‚Šã¾ã—ãŸã€ç­‰ï¼‰
âŒ å‚åŠ è€…åŒå£«ã®ä¼šè©±ã¸ã®å‰²ã‚Šè¾¼ã¿
âŒ é€£ç¶šç™ºè¨€ï¼ˆå‰å›ç™ºè¨€ã‹ã‚‰æœ€ä½2åˆ†ç©ºã‘ã‚‹ï¼‰
âŒ é•·ã„èª¬æ˜ï¼ˆ20ç§’ä»¥å†…ã«åã‚ã‚‹ï¼‰

ã€ç™ºè¨€ã‚¹ã‚¿ã‚¤ãƒ«ã€‘
- ç°¡æ½”ï¼ˆ20ç§’ä»¥å†…ï¼‰
- è£œåŠ©çš„ãªç«‹å ´ã‚’ä¿ã¤
- å…·ä½“çš„ãªãƒ‡ãƒ¼ã‚¿ã‚„äº‹ä¾‹ã‚’äº¤ãˆã¦
- ã€Œã€œã¨æ€ã„ã¾ã™ã€ã§ã¯ãªãã€Œã€œã§ã™ã€ã¨æ–­å®šçš„ã«

ã‚ãªãŸã¯ä¼šè­°ã®é‚ªé­”ã‚’ã—ãªã„ã€è³¢ã„è£œåŠ©è€…ã§ã™ã€‚`,
              voice: "alloy",
              input_audio_format: "pcm16",
              output_audio_format: "pcm16",
              input_audio_transcription: {
                model: "whisper-1",
              },
              turn_detection: {
                type: "server_vad",
                threshold: 0.5,
                silence_duration_ms: 700, // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—çµ‚ã‚ã£ãŸã¨åˆ¤å®šã™ã‚‹ã¾ã§ã®æ²ˆé»™æ™‚é–“
                create_response: false, // è‡ªå‹•å¿œç­”OFFï¼ˆã‚²ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ã§åˆ¶å¾¡ï¼‰
              },
            },
          };

          dc.send(JSON.stringify(sessionConfig));
          console.log("Session config sent:", sessionConfig);
        };

        dc.onmessage = (event) => {
          try {
            const data = JSON.parse(event.data);
            handleRealtimeEvent(data);
          } catch (err) {
            console.error("Failed to parse data channel message:", err);
          }
        };

        dc.onerror = (error) => {
          console.error("Data channel error:", error);
        };

        dc.onclose = () => {
          console.log("Data channel closed");
        };

        // 7. SDP Offerä½œæˆ
        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);
        console.log("SDP offer created");

        // 8. OpenAI Realtime APIã«SDP Offerã‚’é€ä¿¡
        console.log("Sending SDP offer to OpenAI...");
        const sdpResponse = await fetch(
          "https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17",
          {
            method: "POST",
            headers: {
              Authorization: `Bearer ${openaiEphemeralKey}`,
              "Content-Type": "application/sdp",
            },
            body: offer.sdp,
          }
        );

        if (!sdpResponse.ok) {
          const errorText = await sdpResponse.text();
          throw new Error(`SDP exchange failed: ${errorText}`);
        }

        // 9. SDP Answerã‚’å—ã‘å–ã£ã¦è¨­å®š
        const answerSdp = await sdpResponse.text();
        const answer: RTCSessionDescriptionInit = {
          type: "answer",
          sdp: answerSdp,
        };
        await pc.setRemoteDescription(answer);
        console.log("SDP answer received and set");

        // 10. æ¥ç¶šçŠ¶æ…‹ç›£è¦–
        pc.oniceconnectionstatechange = () => {
          console.log("ICE connection state:", pc.iceConnectionState);
          if (pc.iceConnectionState === "connected") {
            setIsConnected(true);
          } else if (
            pc.iceConnectionState === "failed" ||
            pc.iceConnectionState === "disconnected"
          ) {
            setIsConnected(false);
          }
        };

        pc.onconnectionstatechange = () => {
          console.log("Connection state:", pc.connectionState);
        };

        peerConnectionRef.current = pc;
        console.log("WebRTC connection established");
      } catch (err: any) {
        console.error("Failed to connect Realtime AI:", err);
        setError(err.message);
        throw err;
      }
    },
    [meetingId, onTranscript, onAIResponse]
  );

  /**
   * AIå¿œç­”ã‚’ãƒˆãƒªã‚¬ãƒ¼
   */
  const triggerAIResponse = useCallback(
    (reason: string, context?: string) => {
      console.log("ğŸ¤– Triggering AI response:", reason);

      if (!dataChannelRef.current) {
        console.error("Data channel not ready");
        return;
      }

      // ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã¯ã€ä¼šè©±ã‚¢ã‚¤ãƒ†ãƒ ã¨ã—ã¦è¿½åŠ 
      if (context) {
        console.log("Adding conversation context:", context);
        dataChannelRef.current.send(
          JSON.stringify({
            type: "conversation.item.create",
            item: {
              type: "message",
              role: "user",
              content: [
                {
                  type: "input_text",
                  text: `ã€ç›´è¿‘ã®ä¼šè©±ã€‘\n${context}\n\nä¸Šè¨˜ã®ä¼šè©±ã‚’è¸ã¾ãˆã¦ã€é©åˆ‡ã«ã‚³ãƒ¡ãƒ³ãƒˆã—ã¦ãã ã•ã„ã€‚`,
                },
              ],
            },
          })
        );
      }

      // response.createã‚¤ãƒ™ãƒ³ãƒˆã‚’é€ä¿¡
      dataChannelRef.current.send(
        JSON.stringify({
          type: "response.create",
        })
      );

      lastAIResponseTimeRef.current = Date.now();
    },
    []
  );

  /**
   * ã‚²ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯: AIãŒç™ºè¨€ã™ã¹ãã‹åˆ¤å®š
   */
  const analyzeAndTriggerResponse = useCallback(
    (transcript: string, speaker: string) => {
      console.log("Analyzing transcript for trigger:", { transcript, speaker });

      // æœ€å¾Œã®AIå¿œç­”ã‹ã‚‰2åˆ†ä»¥å†…ã¯ç™ºè¨€ã—ãªã„
      const timeSinceLastResponse = Date.now() - lastAIResponseTimeRef.current;
      if (timeSinceLastResponse < 120000) {
        console.log("Skip: Too soon after last AI response");
        return false;
      }

      const lowerTranscript = transcript.toLowerCase();

      // æ¡ä»¶1: ç›´æ¥æŒ‡å
      if (
        transcript.includes("Miton") ||
        transcript.includes("miton") ||
        lowerTranscript.includes("ai") ||
        transcript.includes("ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
      ) {
        console.log("âœ… Trigger: Direct call detected");
        triggerAIResponse("direct_call");
        return true;
      }

      // æ¡ä»¶2: è¦ç´„ä¾é ¼
      if (
        transcript.includes("ã¾ã¨ã‚") ||
        transcript.includes("æ•´ç†") ||
        transcript.includes("è¦ç´„")
      ) {
        console.log("âœ… Trigger: Summary request detected");
        triggerAIResponse("summary_request");
        return true;
      }

      // æ¡ä»¶3: è³ªå•å½¢å¼
      if (
        transcript.includes("ï¼Ÿ") ||
        transcript.includes("ã©ã†æ€") ||
        transcript.includes("æ„è¦‹") ||
        transcript.includes("è€ƒãˆ")
      ) {
        console.log("âœ… Trigger: Question detected");
        triggerAIResponse("question");
        return true;
      }

      // æ¡ä»¶4: ç™ºè¨€æ™‚é–“è¿½è·¡ï¼ˆ30ç§’ä»¥ä¸Šã®é•·ã„ç™ºè¨€ï¼‰
      const speakerStartTime = speakerStartTimeRef.current[speaker];
      if (speakerStartTime) {
        const speakingDuration = Date.now() - speakerStartTime;
        if (speakingDuration > 30000) {
          console.log("âœ… Trigger: Long speech (>30s), offer summary");
          triggerAIResponse("long_speech");
          speakerStartTimeRef.current[speaker] = Date.now(); // ãƒªã‚»ãƒƒãƒˆ
          return true;
        }
      } else {
        // è©±è€…ã®ç™ºè¨€é–‹å§‹æ™‚åˆ»ã‚’è¨˜éŒ²
        speakerStartTimeRef.current[speaker] = Date.now();
      }

      console.log("Skip: No trigger condition met");
      return false;
    },
    [triggerAIResponse]
  );

  /**
   * æ²ˆé»™æ¤œå‡ºã‚¿ã‚¤ãƒãƒ¼ã‚’é–‹å§‹
   */
  const startSilenceTimer = useCallback(() => {
    // æ—¢å­˜ã®ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
    if (silenceTimerRef.current) {
      clearTimeout(silenceTimerRef.current);
    }

    // 10ç§’å¾Œã«æ²ˆé»™ãƒã‚§ãƒƒã‚¯
    silenceTimerRef.current = setTimeout(() => {
      const silenceDuration = Date.now() - lastSpeechTimeRef.current;

      if (silenceDuration >= 10000) {
        console.log("âœ… Trigger: Silence detected (>10s)");

        // ç›´è¿‘ã®ä¼šè©±ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦æ¸¡ã™
        const recentConversation = conversationHistoryRef.current
          .slice(-5) // æœ€æ–°5ä»¶
          .map((t) => `${t.speaker}: ${t.text}`)
          .join("\n");

        if (recentConversation) {
          triggerAIResponse("silence", recentConversation);
        } else {
          triggerAIResponse("silence");
        }
      }
    }, 10000);
  }, [triggerAIResponse]);

  /**
   * OpenAI Realtime APIã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†
   */
  const handleRealtimeEvent = useCallback(
    (event: any) => {
      console.log("Realtime event:", event.type, event);

      switch (event.type) {
        case "session.created":
          console.log("Session created:", event.session);
          break;

        case "session.updated":
          console.log("Session updated:", event.session);
          break;

        case "conversation.item.input_audio_transcription.completed":
          // éŸ³å£°å…¥åŠ›ã®æ–‡å­—èµ·ã“ã—å®Œäº†
          const transcript: Transcript = {
            id: event.item_id,
            speaker: "Speaker 1", // TODO: è©±è€…è­˜åˆ¥
            text: event.transcript,
            timestamp: new Date().toISOString(),
            isFinal: true,
          };
          console.log("Transcription completed:", transcript);
          onTranscript(transcript);

          // ä¼šè©±å±¥æ­´ã«è¿½åŠ ï¼ˆæœ€æ–°10ä»¶ã¾ã§ä¿æŒï¼‰
          conversationHistoryRef.current = [
            ...conversationHistoryRef.current.slice(-9), // æœ€æ–°9ä»¶ã‚’ä¿æŒ
            transcript,
          ];

          // ç™ºè¨€ãŒã‚ã£ãŸã®ã§ã€æœ€å¾Œã®ç™ºè¨€æ™‚åˆ»ã‚’æ›´æ–°
          lastSpeechTimeRef.current = Date.now();

          // ã‚²ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè¡Œ
          analyzeAndTriggerResponse(event.transcript, transcript.speaker);

          // æ²ˆé»™æ¤œå‡ºã‚¿ã‚¤ãƒãƒ¼ã‚’é–‹å§‹
          startSilenceTimer();
          break;

        case "response.audio_transcript.delta":
          // AIå¿œç­”ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
          console.log("AI response text delta:", event.delta);
          break;

        case "response.audio_transcript.done":
          // AIå¿œç­”ã®ãƒ†ã‚­ã‚¹ãƒˆå®Œäº†
          const aiResponse: AIResponse = {
            text: event.transcript,
            timestamp: new Date().toISOString(),
          };
          console.log("AI response completed:", aiResponse);
          onAIResponse(aiResponse);
          break;

        case "response.done":
          console.log("Response done:", event);

          // ä½¿ç”¨é‡æƒ…å ±ã‚’å–å¾—
          if (event.response?.usage) {
            const usage = event.response.usage;
            console.log("ğŸ“Š Response Usage:", usage);

            // ç´¯ç©ä½¿ç”¨é‡ã‚’æ›´æ–°
            usageRef.current.totalInputTokens += usage.input_tokens || 0;
            usageRef.current.totalOutputTokens += usage.output_tokens || 0;
            usageRef.current.totalInputAudioTokens +=
              usage.input_token_details?.audio_tokens || 0;
            usageRef.current.totalOutputAudioTokens +=
              usage.output_token_details?.audio_tokens || 0;
            usageRef.current.responseCount += 1;

            // æ–™é‡‘è¨ˆç®—
            const cost = calculateCost(
              usage.input_tokens || 0,
              usage.output_tokens || 0,
              usage.input_token_details?.audio_tokens || 0,
              usage.output_token_details?.audio_tokens || 0
            );

            usageRef.current.totalCostUSD += cost.totalCostUSD;
            usageRef.current.totalCostJPY += cost.totalCostJPY;

            // ã“ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
            console.log(`ğŸ’° ã“ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æ–™é‡‘:
  - ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›: ${usage.input_token_details?.text_tokens || 0} tokens ($${cost.textInputCost.toFixed(6)} / Â¥${(cost.textInputCost * 154).toFixed(2)})
  - ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›: ${usage.output_token_details?.text_tokens || 0} tokens ($${cost.textOutputCost.toFixed(6)} / Â¥${(cost.textOutputCost * 154).toFixed(2)})
  - éŸ³å£°å…¥åŠ›: ${usage.input_token_details?.audio_tokens || 0} tokens ($${cost.audioInputCost.toFixed(6)} / Â¥${(cost.audioInputCost * 154).toFixed(2)})
  - éŸ³å£°å‡ºåŠ›: ${usage.output_token_details?.audio_tokens || 0} tokens ($${cost.audioOutputCost.toFixed(6)} / Â¥${(cost.audioOutputCost * 154).toFixed(2)})
  - åˆè¨ˆ: $${cost.totalCostUSD.toFixed(6)} / Â¥${cost.totalCostJPY.toFixed(2)}`);

            // ã‚»ãƒƒã‚·ãƒ§ãƒ³ç´¯ç©æ–™é‡‘ã‚’ãƒ­ã‚°å‡ºåŠ›
            console.log(`ğŸ’µ ã‚»ãƒƒã‚·ãƒ§ãƒ³ç´¯ç©æ–™é‡‘:
  - ç·å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³: ${usageRef.current.totalInputTokens.toLocaleString()}
  - ç·å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³: ${usageRef.current.totalOutputTokens.toLocaleString()}
  - ç·éŸ³å£°å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³: ${usageRef.current.totalInputAudioTokens.toLocaleString()}
  - ç·éŸ³å£°å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³: ${usageRef.current.totalOutputAudioTokens.toLocaleString()}
  - AIå¿œç­”å›æ•°: ${usageRef.current.responseCount}
  - ç´¯ç©è²»ç”¨: $${usageRef.current.totalCostUSD.toFixed(4)} USD (Â¥${usageRef.current.totalCostJPY.toFixed(0)} å††)`);
          }
          break;

        case "error":
          console.error("Realtime API error:", event.error);
          setError(event.error.message);
          break;
      }
    },
    [onTranscript, onAIResponse, analyzeAndTriggerResponse, startSilenceTimer]
  );

  /**
   * æ¥ç¶šçµ‚äº†
   */
  const disconnect = useCallback(() => {
    console.log("Disconnecting WebRTC...");

    // æœ€çµ‚çš„ãªæ–™é‡‘ã‚µãƒãƒªãƒ¼ã‚’å‡ºåŠ›
    if (usageRef.current.responseCount > 0) {
      console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº† - æ–™é‡‘ã‚µãƒãƒªãƒ¼                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ AIå¿œç­”å›æ•°: ${usageRef.current.responseCount.toString().padEnd(43)}â•‘
â•‘ ç·å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³: ${usageRef.current.totalInputTokens.toLocaleString().padEnd(39)}â•‘
â•‘ ç·å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³: ${usageRef.current.totalOutputTokens.toLocaleString().padEnd(39)}â•‘
â•‘ ç·éŸ³å£°å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³: ${usageRef.current.totalInputAudioTokens.toLocaleString().padEnd(35)}â•‘
â•‘ ç·éŸ³å£°å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³: ${usageRef.current.totalOutputAudioTokens.toLocaleString().padEnd(35)}â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸ’µ åˆè¨ˆè²»ç”¨: $${usageRef.current.totalCostUSD.toFixed(4)} USD (Â¥${usageRef.current.totalCostJPY.toFixed(0)} å††)      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      `);

      // æ¦‚ç®—ï¼š1æ™‚é–“ä¼šè­°ã®å ´åˆã®æ¨å®šè²»ç”¨
      const sessionDurationMinutes =
        (Date.now() - lastSpeechTimeRef.current) / 60000;
      if (sessionDurationMinutes > 0) {
        const costPerHourUSD =
          (usageRef.current.totalCostUSD / sessionDurationMinutes) * 60;
        const costPerHourJPY =
          (usageRef.current.totalCostJPY / sessionDurationMinutes) * 60;
        console.log(
          `ğŸ“ˆ æ¨å®š: 1æ™‚é–“ä¼šè­°ã®å ´åˆ ç´„ $${costPerHourUSD.toFixed(2)} USD (Â¥${costPerHourJPY.toFixed(0)} å††)`
        );
      }
    }

    // æ²ˆé»™æ¤œå‡ºã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
    if (silenceTimerRef.current) {
      clearTimeout(silenceTimerRef.current);
      silenceTimerRef.current = null;
    }

    if (dataChannelRef.current) {
      dataChannelRef.current.close();
      dataChannelRef.current = null;
    }

    if (peerConnectionRef.current) {
      peerConnectionRef.current.close();
      peerConnectionRef.current = null;
    }

    if (audioElementRef.current) {
      audioElementRef.current.pause();
      audioElementRef.current.srcObject = null;
      audioElementRef.current = null;
    }

    setIsConnected(false);

    // ä½¿ç”¨é‡ã‚’ãƒªã‚»ãƒƒãƒˆ
    usageRef.current = {
      totalInputTokens: 0,
      totalOutputTokens: 0,
      totalInputAudioTokens: 0,
      totalOutputAudioTokens: 0,
      totalCostUSD: 0,
      totalCostJPY: 0,
      responseCount: 0,
    };
  }, []);

  return {
    connect,
    disconnect,
    isConnected,
    error,
  };
}
