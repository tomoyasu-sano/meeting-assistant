"use client";

import React, { useState, useRef, useEffect } from "react";
import { v4 as uuidv4 } from "uuid";

export default function STTTestPage() {
  const [sessionId] = useState(() => uuidv4());
  const [isRecording, setIsRecording] = useState(false);
  const [transcripts, setTranscripts] = useState<any[]>([]);
  const [error, setError] = useState<string | null>(null);
  const [stats, setStats] = useState({ chunksUploaded: 0, bytesUploaded: 0 });

  const eventSourceRef = useRef<EventSource | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const workletNodeRef = useRef<AudioWorkletNode | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const uploadIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const pcmChunksRef = useRef<Int16Array[]>([]);
  const sequenceRef = useRef(0);

  // éŒ²éŸ³é–‹å§‹
  const startRecording = async () => {
    try {
      setError(null);
      setTranscripts([]);
      setStats({ chunksUploaded: 0, bytesUploaded: 0 });

      console.log("[STT Test] ğŸ¤ Starting...", { sessionId });

      // 1. SSEæ¥ç¶š
      const eventSource = new EventSource(`/api/stt/test?sessionId=${sessionId}`);
      eventSourceRef.current = eventSource;

      eventSource.addEventListener("ready", () => {
        console.log("[STT Test] âœ… SSE Ready");
      });

      eventSource.addEventListener("partial", (e) => {
        const data = JSON.parse(e.data);
        console.log("[STT Test] ğŸ“ Partial:", data.text);
        setTranscripts((prev) => {
          const filtered = prev.filter((t) => t.isFinal);
          return [...filtered, { ...data, id: Date.now() }];
        });
      });

      eventSource.addEventListener("final", (e) => {
        const data = JSON.parse(e.data);
        console.log("[STT Test] âœ… Final:", data.text);
        setTranscripts((prev) => {
          const filtered = prev.filter((t) => t.isFinal);
          return [...filtered, { ...data, id: Date.now() }];
        });
      });

      eventSource.addEventListener("error", (e: any) => {
        console.error("[STT Test] âŒ SSE Error", e);
        setError("SSE connection error");
      });

      // 2. AudioWorklet setup
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount: 1,
          sampleRate: 16000,
          echoCancellation: true,
          noiseSuppression: true,
        },
      });
      mediaStreamRef.current = stream;

      const AudioContextCtor = (window.AudioContext ||
        (window as any).webkitAudioContext) as typeof AudioContext;
      const audioContext = new AudioContextCtor({ sampleRate: 16000 });
      audioContextRef.current = audioContext;

      await audioContext.audioWorklet.addModule("/worklets/pcm16-processor.js");

      const source = audioContext.createMediaStreamSource(stream);
      const workletNode = new AudioWorkletNode(audioContext, "pcm16-processor");
      workletNodeRef.current = workletNode;

      workletNode.port.onmessage = ({ data }) => {
        if (data instanceof Int16Array) {
          pcmChunksRef.current.push(data);
        } else if (data?.buffer) {
          pcmChunksRef.current.push(new Int16Array(data.buffer));
        }
      };

      source.connect(workletNode);
      workletNode.connect(audioContext.destination);

      console.log("[STT Test] ğŸµ Audio pipeline ready");

      // 3. 500msã”ã¨ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
      uploadIntervalRef.current = setInterval(async () => {
        if (pcmChunksRef.current.length === 0) return;

        const chunks = pcmChunksRef.current.splice(0);
        const totalSamples = chunks.reduce((acc, chunk) => acc + chunk.length, 0);
        const combined = new Int16Array(totalSamples);

        let offset = 0;
        for (const chunk of chunks) {
          combined.set(chunk, offset);
          offset += chunk.length;
        }

        const audioBlob = new Blob([combined.buffer], { type: "audio/pcm" });

        const formData = new FormData();
        formData.append("sessionId", sessionId);
        formData.append("audio", audioBlob);
        formData.append("sequence", sequenceRef.current.toString());

        try {
          const response = await fetch("/api/stt/test-upload", {
            method: "POST",
            body: formData,
          });

          if (response.ok) {
            setStats((prev) => ({
              chunksUploaded: prev.chunksUploaded + 1,
              bytesUploaded: prev.bytesUploaded + audioBlob.size,
            }));
            sequenceRef.current++;
          }
        } catch (uploadError) {
          console.error("[STT Test] Upload error", uploadError);
        }
      }, 500);

      setIsRecording(true);
    } catch (err) {
      console.error("[STT Test] Start error", err);
      setError(err instanceof Error ? err.message : "Failed to start");
    }
  };

  // éŒ²éŸ³åœæ­¢
  const stopRecording = () => {
    console.log("[STT Test] ğŸ›‘ Stopping...");

    if (uploadIntervalRef.current) {
      clearInterval(uploadIntervalRef.current);
      uploadIntervalRef.current = null;
    }

    if (workletNodeRef.current) {
      workletNodeRef.current.port.onmessage = null;
      workletNodeRef.current.disconnect();
      workletNodeRef.current = null;
    }

    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach((track) => track.stop());
      mediaStreamRef.current = null;
    }

    if (eventSourceRef.current) {
      eventSourceRef.current.close();
      eventSourceRef.current = null;
    }

    pcmChunksRef.current = [];
    sequenceRef.current = 0;
    setIsRecording(false);
  };

  // Cleanup
  useEffect(() => {
    return () => {
      stopRecording();
    };
  }, []);

  return (
    <div className="min-h-screen bg-gray-50 py-8">
      <div className="container mx-auto max-w-4xl px-4">
        <div className="mb-6">
          <h1 className="text-3xl font-bold text-gray-900">
            Speech-to-Text ãƒ†ã‚¹ãƒˆ
          </h1>
          <p className="mt-2 text-gray-600">
            Google Cloud Speech-to-Text APIã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—
          </p>
        </div>

        {/* ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ« */}
        <div className="rounded-lg border border-gray-200 bg-white p-6 shadow-sm mb-6">
          <div className="flex items-center gap-4">
            {!isRecording ? (
              <button
                onClick={startRecording}
                className="rounded-lg bg-red-600 px-6 py-3 text-white font-medium hover:bg-red-700 transition-colors"
              >
                ğŸ¤ éŒ²éŸ³é–‹å§‹
              </button>
            ) : (
              <button
                onClick={stopRecording}
                className="rounded-lg bg-gray-600 px-6 py-3 text-white font-medium hover:bg-gray-700 transition-colors"
              >
                â¹ï¸ éŒ²éŸ³åœæ­¢
              </button>
            )}

            {isRecording && (
              <div className="flex items-center gap-2 text-red-600">
                <span className="inline-block w-3 h-3 bg-red-600 rounded-full animate-pulse"></span>
                <span className="font-medium">éŒ²éŸ³ä¸­...</span>
              </div>
            )}
          </div>

          {/* çµ±è¨ˆæƒ…å ± */}
          {isRecording && (
            <div className="mt-4 pt-4 border-t border-gray-200">
              <div className="grid grid-cols-2 gap-4 text-sm">
                <div>
                  <span className="text-gray-600">ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒãƒ£ãƒ³ã‚¯æ•°ï¼š</span>
                  <span className="font-mono font-semibold ml-2">
                    {stats.chunksUploaded}
                  </span>
                </div>
                <div>
                  <span className="text-gray-600">é€ä¿¡ãƒ‡ãƒ¼ã‚¿é‡ï¼š</span>
                  <span className="font-mono font-semibold ml-2">
                    {(stats.bytesUploaded / 1024).toFixed(1)} KB
                  </span>
                </div>
              </div>
            </div>
          )}
        </div>

        {/* ã‚¨ãƒ©ãƒ¼ */}
        {error && (
          <div className="rounded-lg border border-red-200 bg-red-50 p-4 mb-6">
            <p className="text-red-800">âŒ {error}</p>
          </div>
        )}

        {/* æ–‡å­—èµ·ã“ã—çµæœ */}
        <div className="rounded-lg border border-gray-200 bg-white p-6 shadow-sm">
          <h2 className="text-lg font-semibold text-gray-900 mb-4">
            æ–‡å­—èµ·ã“ã—çµæœ
          </h2>

          <div className="min-h-[300px] space-y-3">
            {transcripts.length === 0 ? (
              <p className="text-gray-500">éŒ²éŸ³ã‚’é–‹å§‹ã™ã‚‹ã¨ã€ã“ã“ã«æ–‡å­—èµ·ã“ã—çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™</p>
            ) : (
              transcripts.map((t) => (
                <div
                  key={t.id}
                  className={`p-3 rounded-lg ${
                    t.isFinal
                      ? "bg-blue-50 border border-blue-200"
                      : "bg-gray-50 border border-gray-200"
                  }`}
                >
                  <p className="text-gray-900">{t.text}</p>
                  {t.isFinal && t.confidence !== undefined && (
                    <p className="text-xs text-gray-600 mt-1">
                      ä¿¡é ¼åº¦: {(t.confidence * 100).toFixed(1)}%
                    </p>
                  )}
                </div>
              ))
            )}
          </div>
        </div>

        {/* èª¬æ˜ */}
        <div className="rounded-lg border border-blue-200 bg-blue-50 p-6 shadow-sm mt-6">
          <h3 className="text-sm font-semibold text-blue-900 mb-2">
            ã“ã®ãƒ†ã‚¹ãƒˆã«ã¤ã„ã¦
          </h3>
          <ul className="text-sm text-blue-800 space-y-1">
            <li>â€¢ Google Cloud Speech-to-Text v1 API ã‚’ä½¿ç”¨</li>
            <li>â€¢ ãƒ¢ãƒ‡ãƒ«: latest_longï¼ˆé«˜ç²¾åº¦ãƒ»é•·å°ºå¯¾å¿œï¼‰</li>
            <li>â€¢ éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: LINEAR16, 16kHz, Mono</li>
            <li>â€¢ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èªè­˜ï¼ˆinterim + final resultsï¼‰</li>
          </ul>
        </div>
      </div>
    </div>
  );
}
